	.file	"jfdctfst.c"
	.text
	.globl	jpeg_fdct_ifast                 # -- Begin function jpeg_fdct_ifast
	.p2align	5
	.type	jpeg_fdct_ifast,@function
jpeg_fdct_ifast:                        # @jpeg_fdct_ifast
# %bb.0:                                # %entry
	addi.w	$a2, $zero, -8
	ori	$a1, $zero, 181
	ori	$a3, $zero, 98
	ori	$a4, $zero, 139
	ori	$a5, $zero, 334
	ori	$a6, $zero, 0
	lu32i.d	$a6, 1
	move	$a7, $a0
	.p2align	4, , 16
.LBB0_1:                                # %for.body
                                        # =>This Inner Loop Header: Depth=1
	ld.w	$t0, $a7, 0
	ld.w	$t1, $a7, 28
	ld.w	$t2, $a7, 4
	ld.w	$t3, $a7, 24
	add.d	$t4, $t1, $t0
	sub.d	$t0, $t0, $t1
	add.d	$t1, $t3, $t2
	ld.w	$t5, $a7, 8
	ld.w	$t6, $a7, 20
	ld.w	$t7, $a7, 12
	ld.w	$t8, $a7, 16
	sub.d	$t2, $t2, $t3
	add.d	$t3, $t6, $t5
	sub.d	$t5, $t5, $t6
	add.d	$t6, $t8, $t7
	sub.d	$t7, $t7, $t8
	add.d	$t8, $t6, $t4
	sub.d	$t4, $t4, $t6
	add.d	$t6, $t3, $t1
	sub.d	$t1, $t1, $t3
	add.d	$t3, $t8, $t6
	st.w	$t3, $a7, 0
	sub.d	$t3, $t8, $t6
	st.w	$t3, $a7, 16
	add.w	$t1, $t1, $t4
	mul.d	$t1, $t1, $a1
	srli.d	$t1, $t1, 8
	add.d	$t3, $t4, $t1
	st.w	$t3, $a7, 8
	sub.d	$t1, $t4, $t1
	st.w	$t1, $a7, 24
	add.w	$t1, $t7, $t5
	add.w	$t3, $t5, $t2
	add.w	$t2, $t2, $t0
	sub.w	$t4, $t1, $t2
	mul.d	$t4, $t4, $a3
	srli.d	$t4, $t4, 8
	mul.d	$t1, $t1, $a4
	srli.d	$t1, $t1, 8
	add.d	$t1, $t4, $t1
	mul.d	$t2, $t2, $a5
	srli.d	$t2, $t2, 8
	add.d	$t2, $t4, $t2
	mul.d	$t3, $t3, $a1
	srli.d	$t3, $t3, 8
	add.d	$t4, $t0, $t3
	sub.d	$t0, $t0, $t3
	add.d	$t3, $t1, $t0
	st.w	$t3, $a7, 20
	sub.d	$t0, $t0, $t1
	st.w	$t0, $a7, 12
	add.d	$t0, $t2, $t4
	st.w	$t0, $a7, 4
	sub.d	$t0, $t4, $t2
	st.w	$t0, $a7, 28
	bstrpick.d	$a2, $a2, 31, 0
	addi.d	$a2, $a2, 1
	and	$t0, $a2, $a6
	addi.d	$a7, $a7, 32
	beqz	$t0, .LBB0_1
# %bb.2:                                # %vector.body
	xvld	$xr0, $a0, 0
	xvld	$xr1, $a0, 224
	xvld	$xr2, $a0, 32
	xvld	$xr3, $a0, 192
	xvadd.w	$xr5, $xr1, $xr0
	xvsub.w	$xr0, $xr0, $xr1
	xvadd.w	$xr1, $xr3, $xr2
	xvld	$xr4, $a0, 64
	xvld	$xr6, $a0, 160
	xvld	$xr7, $a0, 96
	xvld	$xr8, $a0, 128
	xvsub.w	$xr3, $xr2, $xr3
	xvadd.w	$xr9, $xr6, $xr4
	xvsub.w	$xr2, $xr4, $xr6
	xvadd.w	$xr6, $xr8, $xr7
	xvsub.w	$xr4, $xr7, $xr8
	xvadd.w	$xr7, $xr6, $xr5
	xvsub.w	$xr5, $xr5, $xr6
	xvadd.w	$xr6, $xr9, $xr1
	xvsub.w	$xr1, $xr1, $xr9
	xvadd.w	$xr8, $xr7, $xr6
	xvst	$xr8, $a0, 0
	xvsub.w	$xr6, $xr7, $xr6
	xvst	$xr6, $a0, 128
	xvadd.w	$xr1, $xr1, $xr5
	xvpermi.q	$xr6, $xr1, 1
	vpickve2gr.w	$a1, $vr6, 2
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr6, 3
	vinsgr2vr.d	$vr7, $a1, 1
	vpickve2gr.w	$a1, $vr6, 0
	vinsgr2vr.d	$vr8, $a1, 0
	vpickve2gr.w	$a1, $vr6, 1
	vinsgr2vr.d	$vr8, $a1, 1
	xvpermi.q	$xr8, $xr7, 2
	vpickve2gr.w	$a1, $vr1, 2
	vinsgr2vr.d	$vr6, $a1, 0
	vpickve2gr.w	$a1, $vr1, 3
	vinsgr2vr.d	$vr6, $a1, 1
	vpickve2gr.w	$a1, $vr1, 0
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr1, 1
	vinsgr2vr.d	$vr7, $a1, 1
	xvpermi.q	$xr7, $xr6, 2
	xvrepli.d	$xr1, 181
	xvmul.d	$xr6, $xr7, $xr1
	xvmul.d	$xr7, $xr8, $xr1
	xvsrli.d	$xr7, $xr7, 8
	xvsrli.d	$xr6, $xr6, 8
	xvpickve2gr.d	$a1, $xr6, 0
	vinsgr2vr.w	$vr8, $a1, 0
	xvpickve2gr.d	$a1, $xr6, 1
	vinsgr2vr.w	$vr8, $a1, 1
	xvpickve2gr.d	$a1, $xr6, 2
	vinsgr2vr.w	$vr8, $a1, 2
	xvpickve2gr.d	$a1, $xr6, 3
	vinsgr2vr.w	$vr8, $a1, 3
	xvpickve2gr.d	$a1, $xr7, 0
	vinsgr2vr.w	$vr6, $a1, 0
	xvpickve2gr.d	$a1, $xr7, 1
	vinsgr2vr.w	$vr6, $a1, 1
	xvpickve2gr.d	$a1, $xr7, 2
	vinsgr2vr.w	$vr6, $a1, 2
	xvpickve2gr.d	$a1, $xr7, 3
	vinsgr2vr.w	$vr6, $a1, 3
	xvpermi.q	$xr8, $xr6, 2
	xvadd.w	$xr6, $xr5, $xr8
	xvst	$xr6, $a0, 64
	xvsub.w	$xr5, $xr5, $xr8
	xvst	$xr5, $a0, 192
	xvadd.w	$xr5, $xr4, $xr2
	xvadd.w	$xr2, $xr2, $xr3
	xvadd.w	$xr3, $xr3, $xr0
	xvsub.w	$xr4, $xr5, $xr3
	xvpermi.q	$xr6, $xr4, 1
	vpickve2gr.w	$a1, $vr6, 2
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr6, 3
	vinsgr2vr.d	$vr7, $a1, 1
	vpickve2gr.w	$a1, $vr6, 0
	vinsgr2vr.d	$vr8, $a1, 0
	vpickve2gr.w	$a1, $vr6, 1
	vinsgr2vr.d	$vr8, $a1, 1
	xvpermi.q	$xr8, $xr7, 2
	vpickve2gr.w	$a1, $vr4, 2
	vinsgr2vr.d	$vr6, $a1, 0
	vpickve2gr.w	$a1, $vr4, 3
	vinsgr2vr.d	$vr6, $a1, 1
	vpickve2gr.w	$a1, $vr4, 0
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr4, 1
	vinsgr2vr.d	$vr7, $a1, 1
	xvpermi.q	$xr7, $xr6, 2
	xvrepli.d	$xr4, 98
	xvmul.d	$xr6, $xr7, $xr4
	xvmul.d	$xr4, $xr8, $xr4
	xvsrli.d	$xr7, $xr4, 8
	xvsrli.d	$xr6, $xr6, 8
	xvpickve2gr.d	$a1, $xr6, 0
	vinsgr2vr.w	$vr4, $a1, 0
	xvpickve2gr.d	$a1, $xr6, 1
	vinsgr2vr.w	$vr4, $a1, 1
	xvpickve2gr.d	$a1, $xr6, 2
	vinsgr2vr.w	$vr4, $a1, 2
	xvpickve2gr.d	$a1, $xr6, 3
	vinsgr2vr.w	$vr4, $a1, 3
	xvpickve2gr.d	$a1, $xr7, 0
	vinsgr2vr.w	$vr6, $a1, 0
	xvpickve2gr.d	$a1, $xr7, 1
	vinsgr2vr.w	$vr6, $a1, 1
	xvpickve2gr.d	$a1, $xr7, 2
	vinsgr2vr.w	$vr6, $a1, 2
	xvpickve2gr.d	$a1, $xr7, 3
	vinsgr2vr.w	$vr6, $a1, 3
	xvpermi.q	$xr4, $xr6, 2
	xvpermi.q	$xr6, $xr5, 1
	vpickve2gr.w	$a1, $vr6, 2
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr6, 3
	vinsgr2vr.d	$vr7, $a1, 1
	vpickve2gr.w	$a1, $vr6, 0
	vinsgr2vr.d	$vr8, $a1, 0
	vpickve2gr.w	$a1, $vr6, 1
	vinsgr2vr.d	$vr8, $a1, 1
	xvpermi.q	$xr8, $xr7, 2
	vpickve2gr.w	$a1, $vr5, 2
	vinsgr2vr.d	$vr6, $a1, 0
	vpickve2gr.w	$a1, $vr5, 3
	vinsgr2vr.d	$vr6, $a1, 1
	vpickve2gr.w	$a1, $vr5, 0
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr5, 1
	vinsgr2vr.d	$vr7, $a1, 1
	xvpermi.q	$xr7, $xr6, 2
	xvrepli.d	$xr5, 139
	xvmul.d	$xr6, $xr7, $xr5
	xvmul.d	$xr5, $xr8, $xr5
	xvsrli.d	$xr5, $xr5, 8
	xvsrli.d	$xr6, $xr6, 8
	xvpickve2gr.d	$a1, $xr6, 0
	vinsgr2vr.w	$vr7, $a1, 0
	xvpickve2gr.d	$a1, $xr6, 1
	vinsgr2vr.w	$vr7, $a1, 1
	xvpickve2gr.d	$a1, $xr6, 2
	vinsgr2vr.w	$vr7, $a1, 2
	xvpickve2gr.d	$a1, $xr6, 3
	vinsgr2vr.w	$vr7, $a1, 3
	xvpickve2gr.d	$a1, $xr5, 0
	vinsgr2vr.w	$vr6, $a1, 0
	xvpickve2gr.d	$a1, $xr5, 1
	vinsgr2vr.w	$vr6, $a1, 1
	xvpickve2gr.d	$a1, $xr5, 2
	vinsgr2vr.w	$vr6, $a1, 2
	xvpickve2gr.d	$a1, $xr5, 3
	vinsgr2vr.w	$vr6, $a1, 3
	xvpermi.q	$xr7, $xr6, 2
	xvadd.w	$xr5, $xr4, $xr7
	xvpermi.q	$xr6, $xr3, 1
	vpickve2gr.w	$a1, $vr6, 2
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr6, 3
	vinsgr2vr.d	$vr7, $a1, 1
	vpickve2gr.w	$a1, $vr6, 0
	vinsgr2vr.d	$vr8, $a1, 0
	vpickve2gr.w	$a1, $vr6, 1
	vinsgr2vr.d	$vr8, $a1, 1
	xvpermi.q	$xr8, $xr7, 2
	vpickve2gr.w	$a1, $vr3, 2
	vinsgr2vr.d	$vr6, $a1, 0
	vpickve2gr.w	$a1, $vr3, 3
	vinsgr2vr.d	$vr6, $a1, 1
	vpickve2gr.w	$a1, $vr3, 0
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr3, 1
	vinsgr2vr.d	$vr7, $a1, 1
	xvpermi.q	$xr7, $xr6, 2
	xvrepli.d	$xr3, 334
	xvmul.d	$xr6, $xr7, $xr3
	xvmul.d	$xr3, $xr8, $xr3
	xvsrli.d	$xr3, $xr3, 8
	xvsrli.d	$xr6, $xr6, 8
	xvpickve2gr.d	$a1, $xr6, 0
	vinsgr2vr.w	$vr7, $a1, 0
	xvpickve2gr.d	$a1, $xr6, 1
	vinsgr2vr.w	$vr7, $a1, 1
	xvpickve2gr.d	$a1, $xr6, 2
	vinsgr2vr.w	$vr7, $a1, 2
	xvpickve2gr.d	$a1, $xr6, 3
	vinsgr2vr.w	$vr7, $a1, 3
	xvpickve2gr.d	$a1, $xr3, 0
	vinsgr2vr.w	$vr6, $a1, 0
	xvpickve2gr.d	$a1, $xr3, 1
	vinsgr2vr.w	$vr6, $a1, 1
	xvpickve2gr.d	$a1, $xr3, 2
	vinsgr2vr.w	$vr6, $a1, 2
	xvpickve2gr.d	$a1, $xr3, 3
	vinsgr2vr.w	$vr6, $a1, 3
	xvpermi.q	$xr7, $xr6, 2
	xvadd.w	$xr3, $xr4, $xr7
	xvpermi.q	$xr4, $xr2, 1
	vpickve2gr.w	$a1, $vr4, 2
	vinsgr2vr.d	$vr6, $a1, 0
	vpickve2gr.w	$a1, $vr4, 3
	vinsgr2vr.d	$vr6, $a1, 1
	vpickve2gr.w	$a1, $vr4, 0
	vinsgr2vr.d	$vr7, $a1, 0
	vpickve2gr.w	$a1, $vr4, 1
	vinsgr2vr.d	$vr7, $a1, 1
	xvpermi.q	$xr7, $xr6, 2
	vpickve2gr.w	$a1, $vr2, 2
	vinsgr2vr.d	$vr4, $a1, 0
	vpickve2gr.w	$a1, $vr2, 3
	vinsgr2vr.d	$vr4, $a1, 1
	vpickve2gr.w	$a1, $vr2, 0
	vinsgr2vr.d	$vr6, $a1, 0
	vpickve2gr.w	$a1, $vr2, 1
	vinsgr2vr.d	$vr6, $a1, 1
	xvpermi.q	$xr6, $xr4, 2
	xvmul.d	$xr2, $xr6, $xr1
	xvmul.d	$xr1, $xr7, $xr1
	xvsrli.d	$xr1, $xr1, 8
	xvsrli.d	$xr2, $xr2, 8
	xvpickve2gr.d	$a1, $xr2, 0
	vinsgr2vr.w	$vr4, $a1, 0
	xvpickve2gr.d	$a1, $xr2, 1
	vinsgr2vr.w	$vr4, $a1, 1
	xvpickve2gr.d	$a1, $xr2, 2
	vinsgr2vr.w	$vr4, $a1, 2
	xvpickve2gr.d	$a1, $xr2, 3
	vinsgr2vr.w	$vr4, $a1, 3
	xvpickve2gr.d	$a1, $xr1, 0
	vinsgr2vr.w	$vr2, $a1, 0
	xvpickve2gr.d	$a1, $xr1, 1
	vinsgr2vr.w	$vr2, $a1, 1
	xvpickve2gr.d	$a1, $xr1, 2
	vinsgr2vr.w	$vr2, $a1, 2
	xvpickve2gr.d	$a1, $xr1, 3
	vinsgr2vr.w	$vr2, $a1, 3
	xvpermi.q	$xr4, $xr2, 2
	xvadd.w	$xr1, $xr0, $xr4
	xvsub.w	$xr0, $xr0, $xr4
	xvadd.w	$xr2, $xr5, $xr0
	xvst	$xr2, $a0, 160
	xvsub.w	$xr0, $xr0, $xr5
	xvst	$xr0, $a0, 96
	xvadd.w	$xr0, $xr3, $xr1
	xvst	$xr0, $a0, 32
	xvsub.w	$xr0, $xr1, $xr3
	xvst	$xr0, $a0, 224
	ret
.Lfunc_end0:
	.size	jpeg_fdct_ifast, .Lfunc_end0-jpeg_fdct_ifast
                                        # -- End function
	.section	".note.GNU-stack","",@progbits
	.addrsig
